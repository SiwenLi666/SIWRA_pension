# src/agents/answering_agent.py
import logging
import json
from pathlib import Path
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI
from src.utils.config import SUMMARY_JSON_PATH, VERIFY_ANSWERS, STRUCTURED_ANSWER_TEMPLATES, ANSWER_POST_PROCESSING, ENHANCED_COMPARISON_HANDLING, CONFIDENCE_SCORING, USER_FEEDBACK_MECHANISM
from src.retriever.retriever_tool import RetrieverTool
from src.reasoning.reasoning_utils import ResponseVerifier, AnswerPostProcessor, ComparisonHandler, ConfidenceScorer
from src.graph.state import GraphState, AgentState, UserProfile
from src.feedback.feedback_ui import FeedbackUI

logger = logging.getLogger('answering_agents')


class AnswerAgent:
    def __init__(self):
        self.llm = ChatOpenAI(temperature=0.3, model="gpt-4")
        self.response_verifier = ResponseVerifier() if VERIFY_ANSWERS else None

    def generate(self, state):
        state["status"] = "üîé L√§ser summeringar fr√•n dokument..."
        logger.info(state["status"])

        question =  state.get("question", "")
        logger.info("[generate_answer] Generating answer from summary.json via LLM...")

        try:
            with open(SUMMARY_JSON_PATH, "r", encoding="utf-8") as f:
                summary_data = json.load(f)
        except Exception as e:
            logger.error(f"‚ùå Failed to load summary.json: {e}")
            state["draft_answer"] = "Tyv√§rr, jag kunde inte ladda summeringsfilen."
            return state


        structured_summary = []
        for entry in summary_data.get("agreements", []):
            agreement_name = entry.get("name", "Ok√§nt avtal")
            docs = entry.get("documents", [])
            doc_summaries = [doc.get("summary", "") for doc in docs if doc.get("summary")]
            structured_summary.append(f"Avtal: {agreement_name}\n" + "\n".join(f"- {s}" for s in doc_summaries))


        if not structured_summary:
            logger.warning("‚ö†Ô∏è No summaries found in summary.json")
            state["draft_answer"] = "Tyv√§rr, inga summeringar fanns tillg√§ngliga."
            return state


        prompt = [
            SystemMessage(content=(
                "Du √§r en expert pensionsr√•dgivare. "
                "Du f√•r endast svara baserat p√• inneh√•llet i summeringarna nedan. "
                "summeringarna √§r extraherad fr√•n en vectordatabasen p√• olika pensions avtal"
                "Om du inte hittar ett tydligt svar i summeringarna, svara exakt: 'nej'. "
                "Gissa inte. Hitta ett tydligt matchande svar eller s√§g 'nej'."
            )),
            HumanMessage(content=(
                f"Fr√•ga: '{question}'\n\n"
                "H√§r √§r informationen du kan anv√§nda, grupperad per avtal:\n\n" +
                "\n\n".join(structured_summary) +
                "\n\nOm anv√§ndaren fr√•gar om vilka avtal du har, n√§mn endast avtalsnamnen (t.ex. PA16, SKR2023), inte alla dokument."
                "Om du inte hittar ett tydligt svar i summeringarna, svara exakt: 'nej'. inget annat!"
            ))
        ]

        try:
            response = self.llm.invoke(prompt).content.strip()
            response = response.replace(". ", ".\n")  # crude line-breaks
            logger.debug("[generate_answer] Generating answer...")
            logger.warning(f"[generate_answer] LLM draft answer:\n{response}")
            
            # Verify the answer if enabled
            if VERIFY_ANSWERS and self.response_verifier and response.lower() == "nej":
                logger.info("üîç Answer verification: Initial answer was 'nej', attempting to find better information")
                # If the answer is just 'nej', we need to try a different approach
                state["draft_answer"] = response
                state["response_source"] = "summary_json"
                state["needs_refinement"] = True
                return state
            
            state["draft_answer"] = response
            state["response_source"] = "summary_json"
            return state

        except Exception as e:
            logger.error(f"‚ùå LLM failed to generate answer: {e}")
            state["draft_answer"] = "Tyv√§rr, ett fel uppstod n√§r jag f√∂rs√∂kte besvara fr√•gan."
            state["response_source"] = "summary_json"
            return state


#--------------------------------------------

logger = logging.getLogger(__name__)
class RefinerAgent:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4", temperature=0.7)
        self.retriever = RetrieverTool()
        self.response_verifier = ResponseVerifier() if VERIFY_ANSWERS else None
        self.question_classifier = QuestionClassifier() if STRUCTURED_ANSWER_TEMPLATES else None
        self.post_processor = AnswerPostProcessor() if ANSWER_POST_PROCESSING else None
        self.comparison_handler = ComparisonHandler() if ENHANCED_COMPARISON_HANDLING else None
        self.confidence_scorer = ConfidenceScorer() if CONFIDENCE_SCORING else None
        self.feedback_ui = FeedbackUI() if USER_FEEDBACK_MECHANISM else None

    def refine(self, state):
        state["status"] = "‚úèÔ∏è F√∂rb√§ttrar s√∂kfr√•gan..."

        question = state.get("question", "")
        messages = [
            SystemMessage(content=(
                "Du √§r en expert p√• pensioner och teknisk s√∂koptimering. "
                "Formulera 3‚Äì5 precisa och professionella s√∂kfr√•gor f√∂r en vektordatabas, baserat p√• anv√§ndarens fr√•ga. "
                "Anv√§nd korrekt terminologi fr√•n pensionsavtal (t.ex. 'familjepension', 'efterlevandeskydd') och inkludera agreement_name om relevant."
            )),
            HumanMessage(content=f"Originalf√•ga: {question}")
        ]

        reformulated = self.llm.invoke(messages).content.strip()
        state["reformulated_query"] = reformulated
        logger.warning(f"[refine_answer] Reformulated query:\n{reformulated}")

        # üîç Utf√∂r s√∂kning igen
        docs = self.retriever.retrieve_relevant_docs(reformulated, top_k=3)
        
        # Extract and collect all acronyms and definitions from retrieved documents
        all_acronyms = set()
        all_definitions = {}
        all_target_groups = set()
        
        for doc in docs:
            # Extract acronyms and their definitions
            if "acronyms" in doc.metadata and doc.metadata["acronyms"]:
                for acronym in doc.metadata["acronyms"]:
                    all_acronyms.add(acronym)
            
            # Collect definitions
            if "definitions" in doc.metadata and doc.metadata["definitions"]:
                all_definitions.update(doc.metadata["definitions"])
            
            # Collect target groups
            if "target_groups" in doc.metadata and doc.metadata["target_groups"]:
                all_target_groups.update(doc.metadata["target_groups"])
        
        # Create enhanced context with definitions if relevant
        context = "\n\n".join([doc.page_content for doc in docs])
        
        # Check if the question is about an acronym or term that we have a definition for
        relevant_terms = []
        for term in all_acronyms:
            if term.lower() in question.lower():
                if term in all_definitions:
                    relevant_terms.append((term, all_definitions[term]))
        
        # Add definitions section if we found relevant terms
        definitions_section = ""
        if relevant_terms:
            definitions_section = "\n\nDefinitioner av termer i fr√•gan:\n"
            for term, definition in relevant_terms:
                definitions_section += f"- {term}: {definition}\n"
        
        # Add target group information if relevant
        target_group_section = ""
        if all_target_groups:
            target_group_section = "\n\nM√•lgrupper som n√§mns i dokumenten:\n"
            for group in all_target_groups:
                target_group_section += f"- {group}\n"
        
        # Combine everything
        enhanced_context = context + definitions_section + target_group_section

        # Classify the question type if structured templates are enabled
        question_type = None
        template = None
        if STRUCTURED_ANSWER_TEMPLATES and self.question_classifier:
            question_type = self.question_classifier.classify_question(question)
            template = self.question_classifier.get_template_for_type(question_type)
            logger.info(f"[refine_answer] Question classified as: {question_type}")
        
        # ü§ñ F√∂rs√∂k besvara med ny kontext och eventuell strukturerad mall
        system_content = (
            "Besvara fr√•gan baserat p√• dokumenten nedan. Var konkret, tydlig och anv√§nd korrekt pensionsspr√•k. "
            "Om svaret √§r oklart ‚Äì ge det b√§sta du kan hitta och f√∂rklara eventuella brister. "
            "Om fr√•gan inneh√•ller pensionstermer eller f√∂rkortningar, f√∂rklara dessa i ditt svar. "
            "Om det finns m√•lgruppsinformation, f√∂rklara vad som g√§ller f√∂r olika m√•lgrupper."
        )
        
        # Add template instructions if available
        if template:
            system_content += f"\n\nAnv√§nd f√∂ljande mall f√∂r att strukturera ditt svar:\n{template}"
        
        answer_prompt = [
            SystemMessage(content=system_content),
            HumanMessage(content=f"Fr√•ga: {question}\n\nF√∂rb√§ttrad s√∂kfr√•ga: {reformulated}\n\nDokument och definitioner:\n{enhanced_context}")
        ]

        new_answer = self.llm.invoke(answer_prompt).content.strip()
        logger.info(f"[refine_answer] LLM refined answer:\n{new_answer}")
        
        # Verify the answer if enabled
        if VERIFY_ANSWERS and self.response_verifier:
            doc_contents = [doc.page_content for doc in docs]
            is_sufficient = self.response_verifier.is_response_sufficient(
                question, new_answer, doc_contents
            )
            
            if not is_sufficient:
                logger.warning("‚ö†Ô∏è Answer verification: Response deemed insufficient")
                # Try to improve the answer with more explicit instructions
                fallback_prompt = [
                    SystemMessage(content=(
                        "Du √§r en expert pensionsr√•dgivare. Besvara fr√•gan baserat p√• dokumenten nedan. "
                        "Var konkret och tydlig. Om du inte kan hitta ett bra svar i dokumenten, "
                        "erk√§nn det √§rligt och ge anv√§ndaren b√§sta m√∂jliga information baserat p√• "
                        "vad som faktiskt finns i dokumenten. Undvik att h√§nvisa till information som "
                        "inte finns i dokumenten. F√∂rklara pensionstermer och f√∂rkortningar n√§r det √§r relevant."
                    )),
                    HumanMessage(content=f"Fr√•ga: {question}\n\nDokument och definitioner:\n{enhanced_context}")
                ]
                
                try:
                    improved_answer = self.llm.invoke(fallback_prompt).content.strip()
                    logger.info(f"[refine_answer] Improved answer after verification:\n{improved_answer}")
                    new_answer = improved_answer
                except Exception as e:
                    logger.error(f"‚ùå Failed to generate improved answer: {e}")
                    # Keep the original answer if fallback fails
        
        # Check if this is a comparison question and handle it specially
        is_comparison = False
        if ENHANCED_COMPARISON_HANDLING and self.comparison_handler:
            try:
                is_comparison = self.comparison_handler.is_comparison_question(question)
                if is_comparison:
                    logger.info("üìã Detected comparison question, using specialized handling")
                    doc_contents = [doc.page_content for doc in docs]
                    comparison_answer = self.comparison_handler.generate_structured_comparison(question, doc_contents)
                    new_answer = comparison_answer
                    logger.info("‚úÖ Generated structured comparison response")
            except Exception as e:
                logger.error(f"‚ùå Error in comparison handling: {e}")
                # Continue with normal processing if comparison handling fails
                is_comparison = False
        
        # Apply post-processing if enabled and not a comparison question
        if ANSWER_POST_PROCESSING and self.post_processor and not is_comparison:
            doc_contents = [doc.page_content for doc in docs]
            logger.info("üîÑ Applying answer post-processing")
            processed_answer = self.post_processor.process_answer(question, new_answer, doc_contents)
            
            # Only use the processed answer if it's different from the original
            if processed_answer != new_answer:
                logger.info("‚úÖ Answer was enhanced during post-processing")
                new_answer = processed_answer
            else:
                logger.info("‚ÑπÔ∏è No changes needed during post-processing")
                
        # Add confidence scoring if enabled
        if CONFIDENCE_SCORING and self.confidence_scorer:
            doc_contents = [doc.page_content for doc in docs]
            logger.info("üìä Adding confidence score to answer")
            new_answer = self.confidence_scorer.add_confidence_score_to_answer(question, new_answer, doc_contents)
        
        # Add feedback UI if enabled
        if USER_FEEDBACK_MECHANISM and self.feedback_ui:
            logger.info("üó≥Ô∏è Adding feedback UI to answer")
            feedback_ui = self.feedback_ui.prepare_feedback_ui(question, new_answer)
            new_answer = new_answer + feedback_ui
        
        # üéØ Skicka vidare till slutlig anv√§ndarsvar
        state["draft_answer"] = new_answer
        state["retrieved_docs"] = docs
        return state


# ---------------------------------------------
# Question Classification for Structured Templates

class QuestionClassifier:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.0)  # Use a cheaper model for classification
    
    def classify_question(self, question: str) -> str:
        """
        Classify the question into one of several predefined types to determine
        which answer template to use.
        """
        if not STRUCTURED_ANSWER_TEMPLATES:
            return "general"
            
        prompt = [
            SystemMessage(content=(
                "Du √§r en expert p√• att klassificera fr√•gor om pension. "
                "Analysera fr√•gan och klassificera den i exakt EN av f√∂ljande kategorier:\n"
                "- eligibility: Fr√•gor om vem som kvalificerar sig f√∂r en viss pensionsf√∂rm√•n\n"
                "- calculation: Fr√•gor om hur man ber√§knar pensionsbelopp\n"
                "- comparison: Fr√•gor som j√§mf√∂r olika pensionsavtal eller f√∂rm√•ner\n"
                "- timeline: Fr√•gor om tidpunkter, datum eller tidslinjer f√∂r pension\n"
                "- process: Fr√•gor om processer eller steg f√∂r att ans√∂ka om pension\n"
                "- definition: Fr√•gor som ber om definition av pensionstermer\n"
                "- requirement: Fr√•gor om krav f√∂r att f√• en viss pensionsf√∂rm√•n\n"
                "- general: Alla andra typer av fr√•gor\n\n"
                "Svara ENDAST med kategorinamnet i lowercase, inget annat."
            )),
            HumanMessage(content=question)
        ]
        
        try:
            response = self.llm.invoke(prompt).content.strip().lower()
            # Validate the response is one of our categories
            valid_types = ["eligibility", "calculation", "comparison", "timeline", 
                          "process", "definition", "requirement", "general"]
            
            if response in valid_types:
                return response
            return "general"  # Default if classification fails
        except Exception as e:
            logger.error(f"‚ùå Question classification failed: {e}")
            return "general"  # Default to general template
    
    def get_template_for_type(self, question_type: str) -> str:
        """
        Return a structured template based on the question type.
        """
        templates = {
            "eligibility": (
                "## Beh√∂righet\n"
                "**M√•lgrupp:** [Beskriv vilka personer/grupper som ber√∂rs]\n\n"
                "**Kvalifikationskrav:**\n- [Lista viktiga krav]\n\n"
                "**Undantag:**\n- [Lista eventuella undantag]\n\n"
                "**Ytterligare information:** [L√§gg till relevant kontext]"
            ),
            "calculation": (
                "## Ber√§kning av pension\n"
                "**Formel:** [Beskriv ber√§kningsformeln om tillg√§nglig]\n\n"
                "**Faktorer som p√•verkar ber√§kningen:**\n- [Lista faktorer]\n\n"
                "**Exempel:** [Ge ett exempel om m√∂jligt]\n\n"
                "**Begr√§nsningar:** [N√§mn eventuella tak eller golv]"
            ),
            "comparison": (
                "## J√§mf√∂relse\n"
                "**Alternativ 1: [Namn]**\n- F√∂rdelar: [Lista f√∂rdelar]\n- Nackdelar: [Lista nackdelar]\n\n"
                "**Alternativ 2: [Namn]**\n- F√∂rdelar: [Lista f√∂rdelar]\n- Nackdelar: [Lista nackdelar]\n\n"
                "**Viktigaste skillnaderna:**\n- [Lista huvudskillnader]\n\n"
                "**Rekommendation:** [Om l√§mpligt]"
            ),
            "timeline": (
                "## Tidslinje\n"
                "**Viktiga datum:**\n- [Lista datum och h√§ndelser]\n\n"
                "**Deadlines:**\n- [Lista viktiga deadlines]\n\n"
                "**√ñverg√•ngsperioder:** [Beskriv eventuella √∂verg√•ngsregler]\n\n"
                "**N√§sta steg:** [Vad som h√§nder efter]"
            ),
            "process": (
                "## Process\n"
                "**Steg f√∂r steg:**\n1. [Steg 1]\n2. [Steg 2]\n3. [Forts√§tt efter behov]\n\n"
                "**N√∂dv√§ndiga dokument:**\n- [Lista dokument]\n\n"
                "**Kontaktinformation:** [Om tillg√§nglig]\n\n"
                "**Vanliga problem:** [Lista vanliga problem och l√∂sningar]"
            ),
            "definition": (
                "## Definition\n"
                "**Term:** [Term som definieras]\n\n"
                "**Definition:** [Tydlig definition]\n\n"
                "**Anv√§nds i sammanhang:** [F√∂rklara n√§r/hur termen anv√§nds]\n\n"
                "**Relaterade termer:** [Lista relaterade begrepp]"
            ),
            "requirement": (
                "## Krav\n"
                "**Huvudkrav:**\n- [Lista huvudkrav]\n\n"
                "**Dokumentation som beh√∂vs:**\n- [Lista n√∂dv√§ndiga dokument]\n\n"
                "**Tidsgr√§nser:** [Ange eventuella tidsfrister]\n\n"
                "**Verifieringsprocess:** [Beskriv hur kraven verifieras]"
            ),
            "general": ""  # No specific template for general questions
        }
        
        return templates.get(question_type, "")

# ---------------------------------------------
# src/agents/missing_fields_agent.py


class MissingFieldsAgent:
    def ask(self, state):
        state["status"] = "üì® Formulerar slutgiltigt svar till anv√§ndaren..."

        final_answer = state.get("draft_answer", "Tyv√§rr har jag inget svar.")
        followup = ""

        if state.get("response_source") != "summary_json":
            user_profile = state.get("user_profile", {})
            required_fields = UserProfile.required_fields()
            missing = [f for f in required_fields if f not in user_profile or user_profile[f] is None]

            if missing:
                logger.info("[ask_for_missing_fields] Adding follow-up question for missing fields.")

                field_translations = {
                    "age": "din √•lder",
                    "current_salary": "din nuvarande l√∂n",
                    "employment_type": "vilken typ av anst√§llning du har",
                    "years_of_service": "hur l√§nge du har arbetat",
                    "risk_tolerance": "hur stor risk du √§r villig att ta",
                    "family_situation": "din familjesituation"
                }

                lang = state.get("user_language", "sv")  # use reliably detected lang
                readable_fields = [field_translations.get(f, f) for f in missing]
                # if lang == "sv":
                #     followup = (
                #         "\n\nF√∂r att kunna ge mer personliga r√•d fram√∂ver, "
                #         f"skulle det hj√§lpa om jag kan be f√• lite information om {', '.join(readable_fields)}."
                #     )
                # else:
                #     followup = (
                #         "\n\nTo offer more personalized guidance, "
                #         f"it would help to know your {', '.join(readable_fields)}."
                #     )

        full_response = final_answer #+ followup
        state["response"] = full_response
        state["state"] = AgentState.FINISHED.value

        # logger.warning(f"[ask_for_missing_fields] Follow-up response to user:\n{full_response}")
        return {
            "response": state["response"],
            "status": state.get("status"),
            "user_profile": state.get("user_profile", {}),
            "conversation_id": state.get("conversation_id"),
            "token_usage": state.get("token_usage", []),
            "conversation_history": state.get("conversation_history", []),
            "state": state.get("state", AgentState.FINISHED.value),
        }


