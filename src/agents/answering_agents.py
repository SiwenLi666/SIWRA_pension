# src/agents/answering_agent.py
import logging
import json
from pathlib import Path
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI
from src.utils.config import SUMMARY_JSON_PATH
from src.retriever.retriever_tool import RetrieverTool
from src.reasoning.reasoning_utils import ResponseVerifier
from src.graph.state import GraphState, AgentState, UserProfile

logger = logging.getLogger('answering_agents')


class AnswerAgent:
    def __init__(self):
        self.llm = ChatOpenAI(temperature=0.3, model="gpt-4")

    def generate(self, state):
        state["status"] = "üîé L√§ser summeringar fr√•n dokument..."
        logger.info(state["status"])

        question =  state.get("question", "")
        logger.info("[generate_answer] Generating answer from summary.json via LLM...")

        try:
            with open(SUMMARY_JSON_PATH, "r", encoding="utf-8") as f:
                summary_data = json.load(f)
        except Exception as e:
            logger.error(f"‚ùå Failed to load summary.json: {e}")
            state["draft_answer"] = "Tyv√§rr, jag kunde inte ladda summeringsfilen."
            return state


        structured_summary = []
        for entry in summary_data.get("agreements", []):
            agreement_name = entry.get("name", "Ok√§nt avtal")
            docs = entry.get("documents", [])
            doc_summaries = [doc.get("summary", "") for doc in docs if doc.get("summary")]
            structured_summary.append(f"Avtal: {agreement_name}\n" + "\n".join(f"- {s}" for s in doc_summaries))


        if not structured_summary:
            logger.warning("‚ö†Ô∏è No summaries found in summary.json")
            state["draft_answer"] = "Tyv√§rr, inga summeringar fanns tillg√§ngliga."
            return state


        prompt = [
            SystemMessage(content=(
                "Du √§r en expert pensionsr√•dgivare. "
                "Du f√•r endast svara baserat p√• inneh√•llet i summeringarna nedan. "
                "summeringarna √§r extraherad fr√•n en vectordatabasen p√• olika pensions avtal"
                "Om du inte hittar ett tydligt svar i summeringarna, svara exakt: 'nej'. "
                "Gissa inte. Hitta ett tydligt matchande svar eller s√§g 'nej'."
            )),
            HumanMessage(content=(
                f"Fr√•ga: '{question}'\n\n"
                "H√§r √§r informationen du kan anv√§nda, grupperad per avtal:\n\n" +
                "\n\n".join(structured_summary) +
                "\n\nOm anv√§ndaren fr√•gar om vilka avtal du har, n√§mn endast avtalsnamnen (t.ex. PA16, SKR2023), inte alla dokument."
                "Om du inte hittar ett tydligt svar i summeringarna, svara exakt: 'nej'. inget annat!"
            ))
        ]

        try:
            response = self.llm.invoke(prompt).content.strip()
            response = response.replace(". ", ".\n")  # crude line-breaks
            logger.debug("[generate_answer] Generating answer...")
            logger.warning(f"[generate_answer] LLM draft answer:\n{response}")


            state["draft_answer"] = response
            state["response_source"] = "summary_json"
            return state

        except Exception as e:
            logger.error(f"‚ùå LLM failed to generate answer: {e}")
            state["draft_answer"] = "Tyv√§rr, ett fel uppstod n√§r jag f√∂rs√∂kte besvara fr√•gan."
            state["response_source"] = "summary_json"
            return state


#--------------------------------------------

logger = logging.getLogger(__name__)
class RefinerAgent:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4", temperature=0.7)
        self.retriever = RetrieverTool()
        self.attempts = {}

    def refine(self, state):
        state["status"] = "‚úèÔ∏è Reformulerar fr√•gan..."
        conversation_id = state.get("conversation_id")
        attempts_so_far = self.attempts.get(conversation_id, 0)
        self.attempts[conversation_id] = attempts_so_far + 1
        logger.info(f"[refine_answer] attempt #{attempts_so_far + 1}")
        stage = attempts_so_far + 1
        stage_instruction = {
            #1: "üéØ Det h√§r √§r f√∂rsta f√∂rs√∂ket. Fokusera p√• de mest direkta och precisa begreppen som kan matcha exakt med dokumenttexten.",
            2: "üß† F√∂rs√∂k nu omformulera fr√•gan med lite bredare synonymer, relaterade begrepp eller alternativa tolkningar. T√§nk om anv√§ndaren menade n√•got snarlikt.",
            3: "üö® Detta √§r sista f√∂rs√∂ket. Om inget fungerar, bredda kraftigt. Prova bredare termer, relaterade teman, eller blanda olika angreppss√§tt.",
        }.get(stage, "")

        # 1. Reformulate query
        question =  state.get("question", "")
        messages = [
            SystemMessage(content=(f""" 
üìå Roll
Du √§r en kombination av en erfaren svensk pensionsr√•dgivare och en tekniskt kunnig s√∂kspecialist. Din uppgift √§r att formulera professionella s√∂kfr√•gor (queries) som kan anv√§ndas i en vektordatabas f√∂r att hitta relevanta delar av pensionsavtal.
{stage_instruction}
üí° Du har totalt upp till tre f√∂rs√∂k att f√∂rb√§ttra s√∂kfr√•gan. Det h√§r √§r f√∂rsta f√∂rs√∂ket. Var smart ‚Äì satsa p√• de mest lovande formuleringarna, men spara extrema eller breda strategier till senare om detta misslyckas.
üß© R3-U Modell f√∂r fr√•gef√∂rb√§ttring
1Ô∏è‚É£ Roll (Anv√§ndarens perspektiv)
Identifiera vad anv√§ndaren f√∂rs√∂ker g√∂ra ‚Äì t.ex. f√∂rst√• regler, f√• r√§tt till ers√§ttning, veta hur en viss situation behandlas. Exemplifiera g√§rna: "anv√§ndaren vill veta n√§r och till vem efterlevandepension betalas ut".

2Ô∏è‚É£ Regel (Fackspr√•k)
Hitta r√§tt terminologi och begrepp som anv√§nds i avtalen f√∂r det anv√§ndaren beskriver. Byt ut vardagsspr√•k till formella termer som t.ex. "efterlevandeskydd", "familjepension", "kompletterande efterlevandelivr√§nta".

3Ô∏è‚É£ Resultat (F√∂rv√§ntat svar)
F√∂rutse vilket typ av svar anv√§ndaren vill ha: √§r det en regel? ett undantag? en till√§mpning? ett exempel? Anpassa dina fr√•gor d√§refter.

4Ô∏è‚É£ Uttrycksspecifikation (S√∂kbara fr√•gor)
Formulera 3‚Äì5 konkreta, fokuserade queries som matchar spr√•ket i k√§lldokumenten. obs! varje query skall ha minst 5 nyckelord (exclusive avtalsnamn)som kan beskriva en scenario som kan t√§nkas vara ur ursprungsfr√•ga.
L√§gg till d√§refter "agreement_name" =... som metadata om avtalet √§r angivet. Om m√∂jligt, rikta s√∂kningen mot t.ex. "kapitel='Efterlevandepension'" eller anv√§nd n√§rliggande begrepp.

üõë Viktiga regler
‚ùå Avsluta aldrig med att h√§nvisa anv√§ndaren till annan r√•dgivare eller arbetsgivare. Du √§r senior r√•dgivaren, var professionellt!

‚úÖ Om information saknas, s√§g det ‚Äì men ge alltid v√§gledning om vad som vore n√§sta b√§sta steg.

‚úÖ Anta aldrig att en fr√•ga √§r enkel ‚Äì kontrollera alltid om det kan finnas flera delar (t.ex. olika typer av efterlevandepension).

‚úÖ Undvik att upprepa exakt samma query med sm√• ordskillnader.


"""
            )),
            HumanMessage(content=f"Originalfr√•ga: {question}")
        ]

        reformulated = self.llm.invoke(messages).content.strip()
        logger.warning(f"[refine_answer] Reformulated question: {reformulated}")
        

        # 2. Retrieve again
        new_docs = self.retriever.retrieve_relevant_docs(reformulated, top_k=3)
        context = "\n\n".join([doc.page_content for doc in new_docs])
        
        # 3. Regenerate answer
        answer_prompt = [
            SystemMessage(content=(  
                "Du √§r en svensk pensionsr√•dgivare. Besvara anv√§ndarens fr√•ga s√• tydligt som m√∂jligt "
                "baserat p√• dokumenten nedan. Var konkret, korrekt och pedagogisk.\n\n"
                "‚Ä¢ Svara p√• samma spr√•k som fr√•gan.\n"
                "‚Ä¢ Om du hittar n√•got relevant men inte hela svaret, skriv vad du hittade - men var √§rlig med vad som saknas.\n"
                "‚Ä¢ Gissa inte, men f√∂rs√∂k alltid hj√§lpa anv√§ndaren vidare.\n"
                "‚Ä¢ Om fr√•gan g√§ller ett s√§rskilt pensionsavtal, och det framg√•r i kontexten, n√§mn det i svaret.\n"
                "‚Ä¢ Strukturera g√§rna svaret i punktform eller underrubriker om det f√∂rb√§ttrar l√§sbarheten.\n"
            )),
            HumanMessage(content=f"Originalfr√•ga: {question}, reformerad fr√•ga: {reformulated}\n\nDokumentutdrag:\n{context}")
        ]

        logger.info(f"[refine_answer] Sending to LLM:\n{answer_prompt}")

        new_answer = self.llm.invoke(answer_prompt).content.strip()
        logger.info(f"[refine_answer] LLM refined answer:\n{new_answer}")
        # 4. Decide route


        route = "retry" if attempts_so_far + 1 <= 3 else "give_up"
        state["draft_answer"] = new_answer
        state["retrieved_docs"] = new_docs
        state["refiner_route"] = route

        return state


    def route_refinement(self, state):
        return state.get("refiner_route", "give_up")



#------------------------------
# src/agents/verifier_agent.py


class VerifierAgent:
    def __init__(self):
        self.verifier = ResponseVerifier()

    def verify(self, state):
        """
        Check if 'draft_answer' in state is good enough.
        If generate_answer gives anything other than 'nej', accept it.
        """
        state["status"] = "üìã Utv√§rderar om svaret √§r tillr√§ckligt..."
        question = state.get("question", "")
        draft_answer = state.get("draft_answer", "").strip()
        retrieved_docs = [doc.page_content for doc in state.get("retrieved_docs", [])]

        logger.info("[verify_answer] Verifying draft_answer quality...")

        # ‚úÖ Shortcut: if answer is NOT 'nej', treat it as good
        if draft_answer.lower() != "nej":
            logger.info("[verify_answer] Bypassing verifier ‚Äî draft answer is not 'nej'")
            state["route"] = "good"
            return state

        # Otherwise, do proper check
        is_sufficient = self._custom_check(question, draft_answer, retrieved_docs)
        route = "good" if is_sufficient else "bad"
        state["verifier_route"] = route


        logger.warning(f"[verify_answer] LLM judged sufficiency: {route}")
        return state




    def route_verification(self, state):
        return state.get("verifier_route", "bad")



    def _custom_check(self, question, answer, retrieved_docs):
        return self.verifier.is_response_sufficient(question, answer, retrieved_docs)

# ---------------------------------------------
# src/agents/missing_fields_agent.py


class MissingFieldsAgent:
    def ask(self, state):
        state["status"] = "üì® Formulerar slutgiltigt svar till anv√§ndaren..."

        final_answer = state.get("draft_answer", "Tyv√§rr har jag inget svar.")
        followup = ""

        if state.get("response_source") != "summary_json":
            user_profile = state.get("user_profile", {})
            required_fields = UserProfile.required_fields()
            missing = [f for f in required_fields if f not in user_profile or user_profile[f] is None]

            if missing:
                logger.info("[ask_for_missing_fields] Adding follow-up question for missing fields.")

                field_translations = {
                    "age": "din √•lder",
                    "current_salary": "din nuvarande l√∂n",
                    "employment_type": "vilken typ av anst√§llning du har",
                    "years_of_service": "hur l√§nge du har arbetat",
                    "risk_tolerance": "hur stor risk du √§r villig att ta",
                    "family_situation": "din familjesituation"
                }

                lang = state.get("user_language", "sv")  # use reliably detected lang
                readable_fields = [field_translations.get(f, f) for f in missing]
                # if lang == "sv":
                #     followup = (
                #         "\n\nF√∂r att kunna ge mer personliga r√•d fram√∂ver, "
                #         f"skulle det hj√§lpa om jag kan be f√• lite information om {', '.join(readable_fields)}."
                #     )
                # else:
                #     followup = (
                #         "\n\nTo offer more personalized guidance, "
                #         f"it would help to know your {', '.join(readable_fields)}."
                #     )

        full_response = final_answer #+ followup
        state["response"] = full_response
        state["state"] = AgentState.FINISHED.value

        # logger.warning(f"[ask_for_missing_fields] Follow-up response to user:\n{full_response}")
        return {
            "response": state["response"],
            "status": state.get("status"),
            "user_profile": state.get("user_profile", {}),
            "conversation_id": state.get("conversation_id"),
            "token_usage": state.get("token_usage", []),
            "conversation_history": state.get("conversation_history", []),
            "state": state.get("state", AgentState.FINISHED.value),
        }


