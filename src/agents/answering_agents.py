# src/agents/answering_agent.py
import logging
import json
from pathlib import Path
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI
from src.utils.config import SUMMARY_JSON_PATH
from src.retriever.retriever_tool import RetrieverTool
from src.reasoning.reasoning_utils import ResponseVerifier
from src.graph.state import GraphState, AgentState, UserProfile

logger = logging.getLogger('answering_agents')


class AnswerAgent:
    def __init__(self):
        self.llm = ChatOpenAI(temperature=0.3, model="gpt-4")

    def generate(self, state):
        state["status"] = "üîé L√§ser summeringar fr√•n dokument..."
        logger.info(state["status"])

        question =  state.get("question", "")
        logger.info("[generate_answer] Generating answer from summary.json via LLM...")

        try:
            with open(SUMMARY_JSON_PATH, "r", encoding="utf-8") as f:
                summary_data = json.load(f)
        except Exception as e:
            logger.error(f"‚ùå Failed to load summary.json: {e}")
            state["draft_answer"] = "Tyv√§rr, jag kunde inte ladda summeringsfilen."
            return state


        structured_summary = []
        for entry in summary_data.get("agreements", []):
            agreement_name = entry.get("name", "Ok√§nt avtal")
            docs = entry.get("documents", [])
            doc_summaries = [doc.get("summary", "") for doc in docs if doc.get("summary")]
            structured_summary.append(f"Avtal: {agreement_name}\n" + "\n".join(f"- {s}" for s in doc_summaries))


        if not structured_summary:
            logger.warning("‚ö†Ô∏è No summaries found in summary.json")
            state["draft_answer"] = "Tyv√§rr, inga summeringar fanns tillg√§ngliga."
            return state


        prompt = [
            SystemMessage(content=(
                "Du √§r en expert pensionsr√•dgivare. "
                "Du f√•r endast svara baserat p√• inneh√•llet i summeringarna nedan. "
                "summeringarna √§r extraherad fr√•n en vectordatabasen p√• olika pensions avtal"
                "Om du inte hittar ett tydligt svar i summeringarna, svara exakt: 'nej'. "
                "Gissa inte. Hitta ett tydligt matchande svar eller s√§g 'nej'."
            )),
            HumanMessage(content=(
                f"Fr√•ga: '{question}'\n\n"
                "H√§r √§r informationen du kan anv√§nda, grupperad per avtal:\n\n" +
                "\n\n".join(structured_summary) +
                "\n\nOm anv√§ndaren fr√•gar om vilka avtal du har, n√§mn endast avtalsnamnen (t.ex. PA16, SKR2023), inte alla dokument."
                "Om du inte hittar ett tydligt svar i summeringarna, svara exakt: 'nej'. inget annat!"
            ))
        ]

        try:
            response = self.llm.invoke(prompt).content.strip()
            response = response.replace(". ", ".\n")  # crude line-breaks
            logger.debug("[generate_answer] Generating answer...")
            logger.warning(f"[generate_answer] LLM draft answer:\n{response}")


            state["draft_answer"] = response
            state["response_source"] = "summary_json"
            return state

        except Exception as e:
            logger.error(f"‚ùå LLM failed to generate answer: {e}")
            state["draft_answer"] = "Tyv√§rr, ett fel uppstod n√§r jag f√∂rs√∂kte besvara fr√•gan."
            state["response_source"] = "summary_json"
            return state


#--------------------------------------------

logger = logging.getLogger(__name__)
class RefinerAgent:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4", temperature=0.7)
        self.retriever = RetrieverTool()

    def refine(self, state):
        state["status"] = "‚úèÔ∏è F√∂rb√§ttrar s√∂kfr√•gan..."

        question = state.get("question", "")
        messages = [
            SystemMessage(content=(
                "Du √§r en expert p√• pensioner och teknisk s√∂koptimering. "
                "Formulera 3‚Äì5 precisa och professionella s√∂kfr√•gor f√∂r en vektordatabas, baserat p√• anv√§ndarens fr√•ga. "
                "Anv√§nd korrekt terminologi fr√•n pensionsavtal (t.ex. 'familjepension', 'efterlevandeskydd') och inkludera agreement_name om relevant."
            )),
            HumanMessage(content=f"Originalfr√•ga: {question}")
        ]

        reformulated = self.llm.invoke(messages).content.strip()
        state["reformulated_query"] = reformulated
        logger.warning(f"[refine_answer] Reformulated query:\n{reformulated}")

        # üîç Utf√∂r s√∂kning igen
        docs = self.retriever.retrieve_relevant_docs(reformulated, top_k=3)
        context = "\n\n".join([doc.page_content for doc in docs])

        # üß† F√∂rs√∂k besvara med ny kontext
        answer_prompt = [
            SystemMessage(content=(
                "Besvara fr√•gan baserat p√• dokumenten nedan. Var konkret, tydlig och anv√§nd korrekt pensionsspr√•k. "
                "Om svaret √§r oklart ‚Äì ge det b√§sta du kan hitta och f√∂rklara eventuella brister."
            )),
            HumanMessage(content=f"Fr√•ga: {question}\n\nF√∂rb√§ttrad s√∂kfr√•ga: {reformulated}\n\nDokument:\n{context}")
        ]

        new_answer = self.llm.invoke(answer_prompt).content.strip()
        logger.info(f"[refine_answer] LLM refined answer:\n{new_answer}")

        # üéØ Skicka vidare till slutlig anv√§ndarsvar
        state["draft_answer"] = new_answer
        state["retrieved_docs"] = docs
        return state


# ---------------------------------------------
# src/agents/missing_fields_agent.py


class MissingFieldsAgent:
    def ask(self, state):
        state["status"] = "üì® Formulerar slutgiltigt svar till anv√§ndaren..."

        final_answer = state.get("draft_answer", "Tyv√§rr har jag inget svar.")
        followup = ""

        if state.get("response_source") != "summary_json":
            user_profile = state.get("user_profile", {})
            required_fields = UserProfile.required_fields()
            missing = [f for f in required_fields if f not in user_profile or user_profile[f] is None]

            if missing:
                logger.info("[ask_for_missing_fields] Adding follow-up question for missing fields.")

                field_translations = {
                    "age": "din √•lder",
                    "current_salary": "din nuvarande l√∂n",
                    "employment_type": "vilken typ av anst√§llning du har",
                    "years_of_service": "hur l√§nge du har arbetat",
                    "risk_tolerance": "hur stor risk du √§r villig att ta",
                    "family_situation": "din familjesituation"
                }

                lang = state.get("user_language", "sv")  # use reliably detected lang
                readable_fields = [field_translations.get(f, f) for f in missing]
                # if lang == "sv":
                #     followup = (
                #         "\n\nF√∂r att kunna ge mer personliga r√•d fram√∂ver, "
                #         f"skulle det hj√§lpa om jag kan be f√• lite information om {', '.join(readable_fields)}."
                #     )
                # else:
                #     followup = (
                #         "\n\nTo offer more personalized guidance, "
                #         f"it would help to know your {', '.join(readable_fields)}."
                #     )

        full_response = final_answer #+ followup
        state["response"] = full_response
        state["state"] = AgentState.FINISHED.value

        # logger.warning(f"[ask_for_missing_fields] Follow-up response to user:\n{full_response}")
        return {
            "response": state["response"],
            "status": state.get("status"),
            "user_profile": state.get("user_profile", {}),
            "conversation_id": state.get("conversation_id"),
            "token_usage": state.get("token_usage", []),
            "conversation_history": state.get("conversation_history", []),
            "state": state.get("state", AgentState.FINISHED.value),
        }


