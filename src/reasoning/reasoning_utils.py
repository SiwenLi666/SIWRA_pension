from typing import Optional, Literal, Dict, Any, Tuple
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
import re
import logging
from typing import List, Set
import json

logger = logging.getLogger('reasoning_utils')

class AgreementDetector:
    """
    Detects which pension agreement the user is referring to based on input text.
    """

    def __init__(self):
        self.known_agreements = ["PA16", "SKR2023", "ITP1", "ITP2", "KAP-KL"]

    def detect(self, message: str) -> Optional[str]:
        """
        Scan user message and return the matched agreement if found.
        """
        message_lower = message.lower()
        for agreement in self.known_agreements:
            if agreement.lower() in message_lower:
                return agreement

        # Try fallback with fuzzy matching (e.g. 'pa 16' with space)
        if "pa 16" in message_lower:
            return "PA16"

        return None


# Example usage (can be removed in production):
if __name__ == "__main__":
    detector = AgreementDetector()
    test_input = "Vad g√§ller efterlevnadsskydd i PA16 avdelning 2?"
    print("üîç Agreement detected:", detector.detect(test_input))

#------------------------------------------------

class IntentClassifier:
    """Classifies the user's intent based on their question."""

    def __init__(self):
        self.llm = ChatOpenAI(model_name="gpt-4", temperature=0)

    def classify_intent(self, question: str) -> Literal[
        "general_question", "personal_pension", "agreement_lookup", "ambiguous"]:
        """Categorize the type of user question."""

        system_prompt = """
        Du √§r en AI-assistent som hj√§lper till att klassificera fr√•gor om pensioner.
        Klassificera fr√•gan i en av f√∂ljande kategorier:
        - general_question: En allm√§n fr√•ga om pensioner eller pensionssystem.
        - personal_pension: Anv√§ndaren fr√•gar om sin egen pension eller ger personlig info.
        - agreement_lookup: Fr√•gan g√§ller inneh√•llet i ett specifikt avtal.
        - ambiguous: Det √§r oklart vad anv√§ndaren menar eller den passar inte in i kategorierna.

        Svara enbart med kategorinamn (t.ex. personal_pension) utan f√∂rklaringar.
        """

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=question)
        ]

        response = self.llm.invoke(messages)
        return response.content.strip()

#------------------------------------------------


class ResponseVerifier:
    """
    Uses GPT-4 to evaluate if the AI-generated answer addresses the user's question.
    """

    def __init__(self, model_name="gpt-4", temperature=0.3):
        self.llm = ChatOpenAI(model=model_name, temperature=temperature)

    def is_response_sufficient(self, question: str, answer: str, retrieved_docs: List[str]) -> bool:
        """
        Uses an LLM to judge whether the generated answer is relevant and sufficient.
        """
        context = "\n\n".join(retrieved_docs[:3]) if retrieved_docs else "Inga dokument hittades."
        prompt = (
            "Bed√∂m om f√∂ljande svar besvarar fr√•gan p√• ett tydligt och relevant s√§tt, "
            "baserat p√• tillg√§nglig kontext. Svara endast med 'JA' eller 'NEJ'."
        )
        full_input = [
            SystemMessage(content=prompt),
            HumanMessage(content=f"Fr√•ga: {question}\n\nSvar: {answer}\n\nKontext:\n{context}")
        ]

        try:
            result = self.llm.invoke(full_input)
            decision = result.content.strip().lower()
            logger.info(f"[ResponseVerifier] LLM decision: {decision}")
            return "ja" in decision
        except Exception as e:
            logger.error(f"‚ùå LLM verification failed: {str(e)}")
            return False


class AnswerPostProcessor:
    """
    Post-processes generated answers to ensure they include all requested information
    and address the user's question properly.
    """
    
    def __init__(self, model_name="gpt-4", temperature=0.3):
        self.llm = ChatOpenAI(model=model_name, temperature=temperature)
    
    def extract_key_entities(self, question: str) -> List[str]:
        """
        Extract key entities from the user's question that should be addressed in the answer.
        """
        prompt = [
            SystemMessage(content=(
                "Identifiera de viktigaste nyckelorden och entiteterna i fr√•gan som ett svar m√•ste adressera. "
                "Returnera endast en kommaseparerad lista med 3-5 viktiga termer eller koncept, inga f√∂rklaringar."
            )),
            HumanMessage(content=question)
        ]
        
        try:
            result = self.llm.invoke(prompt)
            entities = [entity.strip() for entity in result.content.split(',')]
            logger.info(f"[AnswerPostProcessor] Extracted entities: {entities}")
            return entities
        except Exception as e:
            logger.error(f"‚ùå Error extracting entities: {e}")
            return []
    
    def identify_missing_information(self, question: str, answer: str, context: List[str]) -> Tuple[bool, List[str]]:
        """
        Identify what information is missing from the answer that should be included.
        Returns a tuple of (has_missing_info, list_of_missing_items)
        """
        context_text = "\n\n".join(context[:3]) if context else "Ingen kontext tillg√§nglig."
        
        prompt = [
            SystemMessage(content=(
                "Du √§r en expert p√• att analysera svar p√• pensionsfr√•gor. "
                "Granska svaret och identifiera viktiga delar fr√•n fr√•gan som inte besvaras tillr√§ckligt. "
                "Om all viktig information finns med, svara 'KOMPLETT'. "
                "Annars, lista de specifika informationspunkter som saknas eller √§r otillr√§ckliga, "
                "en per rad med '-' i b√∂rjan. Var koncis."
            )),
            HumanMessage(content=f"Fr√•ga: {question}\n\nSvar: {answer}\n\nTillg√§nglig kontext:\n{context_text}")
        ]
        
        try:
            result = self.llm.invoke(prompt)
            response = result.content.strip()
            
            if "KOMPLETT" in response.upper():
                return (False, [])
            
            # Extract missing items from the response
            missing_items = []
            for line in response.split('\n'):
                if line.strip().startswith('-'):
                    missing_items.append(line.strip()[1:].strip())
            
            return (True, missing_items)
        except Exception as e:
            logger.error(f"‚ùå Error identifying missing information: {e}")
            return (False, [])
    
    def enhance_answer(self, question: str, original_answer: str, context: List[str], missing_items: List[str]) -> str:
        """
        Enhance the answer by adding missing information identified in the analysis.
        """
        if not missing_items:
            return original_answer
            
        context_text = "\n\n".join(context[:3]) if context else "Ingen kontext tillg√§nglig."
        missing_info = "\n".join([f"- {item}" for item in missing_items])
        
        prompt = [
            SystemMessage(content=(
                "Du √§r en expert p√• pensioner. F√∂rb√§ttra det ursprungliga svaret genom att l√§gga till "
                "information om de saknade punkterna nedan. Integrera informationen naturligt i svaret "
                "s√• att det flyter bra. Anv√§nd endast information fr√•n den tillg√§ngliga kontexten. "
                "Om information saknas i kontexten, erk√§nn det p√• ett professionellt s√§tt."
            )),
            HumanMessage(content=(
                f"Fr√•ga: {question}\n\n"
                f"Ursprungligt svar: {original_answer}\n\n"
                f"Saknad information att inkludera:\n{missing_info}\n\n"
                f"Tillg√§nglig kontext:\n{context_text}"
            ))
        ]
        
        try:
            result = self.llm.invoke(prompt)
            enhanced_answer = result.content.strip()
            logger.info(f"[AnswerPostProcessor] Enhanced answer created")
            return enhanced_answer
        except Exception as e:
            logger.error(f"‚ùå Error enhancing answer: {e}")
            return original_answer  # Return original if enhancement fails
    
    def process_answer(self, question: str, answer: str, context: List[str]) -> str:
        """
        Main method to post-process an answer, ensuring it includes all requested information.
        """
        # Step 1: Check if answer is missing important information
        has_missing_info, missing_items = self.identify_missing_information(question, answer, context)
        
        # Step 2: If information is missing, enhance the answer
        if has_missing_info and missing_items:
            logger.info(f"[AnswerPostProcessor] Missing information detected: {missing_items}")
            enhanced_answer = self.enhance_answer(question, answer, context, missing_items)
            return enhanced_answer
        
        # If no enhancement needed, return the original answer
        return answer


class ComparisonHandler:
    """
    Specialized handler for comparison questions between pension agreements or provisions.
    Provides structured comparison templates and tabular formatting for clear side-by-side comparisons.
    """
    
    def __init__(self, model_name="gpt-4", temperature=0.3):
        self.llm = ChatOpenAI(model=model_name, temperature=temperature)
    
    def is_comparison_question(self, question: str) -> bool:
        """
        Detect if a question is asking for a comparison between different items.
        """
        comparison_indicators = [
            "j√§mf√∂r", "skillnad", "likheter", "j√§mf√∂relse", "versus", "vs", 
            "kontra", "eller", "j√§mf√∂rt med", "i f√∂rh√•llande till", "b√§ttre", 
            "s√§mre", "f√∂rdelar", "nackdelar", "mellan"
        ]
        
        # Check for comparison indicators
        lower_q = question.lower()
        for indicator in comparison_indicators:
            if indicator in lower_q:
                # Verify with more context - ensure it's comparing pension-related items
                prompt = [
                    SystemMessage(content=(
                        "Avg√∂r om f√∂ljande fr√•ga ber om en j√§mf√∂relse mellan olika pensionsavtal, "
                        "f√∂rm√•ner, eller best√§mmelser. Svara endast med 'JA' eller 'NEJ'."
                    )),
                    HumanMessage(content=question)
                ]
                
                try:
                    result = self.llm.invoke(prompt)
                    return "ja" in result.content.lower()
                except Exception as e:
                    logger.error(f"‚ùå Error detecting comparison question: {e}")
                    # If LLM call fails, use simple heuristic
                    return True
        
        return False
    
    def extract_comparison_entities(self, question: str) -> List[str]:
        """
        Extract the entities being compared in the question.
        """
        prompt = [
            SystemMessage(content=(
                "Identifiera de specifika pensionsavtal, f√∂rm√•ner, eller best√§mmelser som j√§mf√∂rs i fr√•gan. "
                "Returnera dem som en kommaseparerad lista. Om inga specifika enheter n√§mns, returnera 'OSPECIFICERAT'."
            )),
            HumanMessage(content=question)
        ]
        
        try:
            result = self.llm.invoke(prompt)
            entities = [entity.strip() for entity in result.content.split(',')]
            if "OSPECIFICERAT" in entities:
                return []
            logger.info(f"[ComparisonHandler] Extracted entities: {entities}")
            return entities
        except Exception as e:
            logger.error(f"‚ùå Error extracting comparison entities: {e}")
            return []
    
    def extract_comparison_aspects(self, question: str) -> List[str]:
        """
        Extract the specific aspects to compare (e.g., retirement age, benefits amount).
        """
        prompt = [
            SystemMessage(content=(
                "Identifiera de specifika aspekter eller egenskaper som ska j√§mf√∂ras i fr√•gan. "
                "Till exempel: pensions√•lder, f√∂rm√•nsbelopp, villkor, etc. "
                "Returnera dem som en kommaseparerad lista. Om inga specifika aspekter n√§mns, returnera 'ALLA'."
            )),
            HumanMessage(content=question)
        ]
        
        try:
            result = self.llm.invoke(prompt)
            aspects = [aspect.strip() for aspect in result.content.split(',')]
            if "ALLA" in aspects:
                # Default aspects if none specified
                return ["Grundl√§ggande villkor", "F√∂rm√•ner", "Pensions√•lder", "S√§rskilda best√§mmelser"]
            logger.info(f"[ComparisonHandler] Extracted aspects: {aspects}")
            return aspects
        except Exception as e:
            logger.error(f"‚ùå Error extracting comparison aspects: {e}")
            return ["Grundl√§ggande villkor", "F√∂rm√•ner", "Pensions√•lder", "S√§rskilda best√§mmelser"]
    
    def generate_comparison_table(self, entities: List[str], aspects: List[str], context: List[str]) -> str:
        """
        Generate a structured comparison table between the entities based on specified aspects.
        """
        context_text = "\n\n".join(context)
        
        # Handle case where entities couldn't be extracted
        if not entities or len(entities) < 2:
            # Try to extract entities from context if not found in question
            prompt = [
                SystemMessage(content=(
                    "Baserat p√• kontexten, identifiera de tv√• eller fler pensionsavtal eller f√∂rm√•ner "
                    "som √§r mest relevanta att j√§mf√∂ra. Returnera dem som en kommaseparerad lista."
                )),
                HumanMessage(content=context_text)
            ]
            
            try:
                result = self.llm.invoke(prompt)
                entities = [entity.strip() for entity in result.content.split(',')]
                logger.info(f"[ComparisonHandler] Extracted entities from context: {entities}")
            except Exception as e:
                logger.error(f"‚ùå Error extracting entities from context: {e}")
                return "Jag kunde inte identifiera specifika pensionsavtal eller f√∂rm√•ner att j√§mf√∂ra. Kan du specificera vilka avtal eller f√∂rm√•ner du vill j√§mf√∂ra?"
        
        # Create table header
        table = "| Aspekt | " + " | ".join(entities) + " |\n"
        table += "| --- | " + " | ".join(["---" for _ in entities]) + " |\n"
        
        # Generate comparison data
        for aspect in aspects:
            prompt = [
                SystemMessage(content=(
                    f"J√§mf√∂r f√∂ljande pensionsavtal/f√∂rm√•ner med avseende p√• '{aspect}'. "
                    f"Ge en kort och koncis j√§mf√∂relse f√∂r varje avtal/f√∂rm√•n. "
                    f"Anv√§nd endast information fr√•n den givna kontexten. "
                    f"Om information saknas f√∂r n√•got avtal, ange 'Information saknas'. "
                    f"Formatera svaret som ett JSON-objekt d√§r nycklarna √§r avtalsnamnen och v√§rdena √§r beskrivningarna."
                )),
                HumanMessage(content=f"Avtal/f√∂rm√•ner att j√§mf√∂ra: {', '.join(entities)}\n\nKontext:\n{context_text}")
            ]
            
            try:
                result = self.llm.invoke(prompt)
                # Try to parse as JSON
                try:
                    comparison_data = json.loads(result.content)
                    row = f"| **{aspect}** | "
                    for entity in entities:
                        if entity in comparison_data:
                            row += f"{comparison_data[entity]} | "
                        else:
                            row += "Information saknas | "
                    table += row + "\n"
                except json.JSONDecodeError:
                    # Fallback if JSON parsing fails
                    logger.warning(f"[ComparisonHandler] JSON parsing failed, using raw response")
                    table += f"| **{aspect}** | {' | '.join(['Information kunde inte struktureras' for _ in entities])} |\n"
            except Exception as e:
                logger.error(f"‚ùå Error generating comparison for aspect {aspect}: {e}")
                table += f"| **{aspect}** | {' | '.join(['Fel vid j√§mf√∂relse' for _ in entities])} |\n"
        
        return table
    
    def generate_comparison_summary(self, entities: List[str], context: List[str]) -> str:
        """
        Generate a summary of key differences and similarities between the entities.
        """
        if not entities or len(entities) < 2:
            return ""
            
        context_text = "\n\n".join(context)
        
        prompt = [
            SystemMessage(content=(
                "Sammanfatta de viktigaste skillnaderna och likheterna mellan de angivna pensionsavtalen/f√∂rm√•nerna. "
                "Fokusera p√• de mest betydelsefulla aspekterna f√∂r en pensionstagare. "
                "Var kortfattad och tydlig."
            )),
            HumanMessage(content=f"Avtal/f√∂rm√•ner att j√§mf√∂ra: {', '.join(entities)}\n\nKontext:\n{context_text}")
        ]
        
        try:
            result = self.llm.invoke(prompt)
            return "\n\n### Sammanfattning av j√§mf√∂relsen\n\n" + result.content
        except Exception as e:
            logger.error(f"‚ùå Error generating comparison summary: {e}")
            return ""
    
    def generate_structured_comparison(self, question: str, context: List[str]) -> str:
        """
        Main method to generate a structured comparison response based on the question and context.
        """
        # Extract entities and aspects to compare
        entities = self.extract_comparison_entities(question)
        aspects = self.extract_comparison_aspects(question)
        
        # Generate comparison table
        comparison_table = self.generate_comparison_table(entities, aspects, context)
        
        # Generate summary
        summary = self.generate_comparison_summary(entities, context)
        
        # Combine into structured response
        response = f"### J√§mf√∂relse mellan {', '.join(entities) if entities else 'pensionsavtal/f√∂rm√•ner'}\n\n"
        response += comparison_table + "\n"
        response += summary
        
        return response


class ConfidenceScorer:
    """
    Evaluates the confidence level of generated answers based on evidence strength,
    context relevance, and answer completeness.
    """
    
    def __init__(self, model_name="gpt-4", temperature=0.2):
        self.llm = ChatOpenAI(model=model_name, temperature=temperature)
    
    def calculate_confidence_score(self, question: str, answer: str, context: List[str]) -> Tuple[float, Dict[str, float]]:
        """
        Calculate a confidence score (0-100%) for the generated answer based on multiple factors.
        Returns the overall score and a breakdown of component scores.
        """
        context_text = "\n\n".join(context[:3]) if context else "Ingen kontext tillg√§nglig."
        
        # Evaluate different aspects of confidence
        evidence_score = self._evaluate_evidence_strength(question, answer, context_text)
        relevance_score = self._evaluate_context_relevance(question, context_text)
        completeness_score = self._evaluate_answer_completeness(question, answer)
        consistency_score = self._evaluate_internal_consistency(answer)
        
        # Calculate weighted overall score
        weights = {
            "evidence": 0.4,      # Evidence strength is most important
            "relevance": 0.3,    # Context relevance is very important
            "completeness": 0.2,  # Answer completeness matters
            "consistency": 0.1    # Internal consistency is a bonus
        }
        
        component_scores = {
            "evidence": evidence_score,
            "relevance": relevance_score,
            "completeness": completeness_score,
            "consistency": consistency_score
        }
        
        overall_score = sum(score * weights[key] for key, score in component_scores.items())
        
        # Round to nearest integer percentage
        overall_score = round(overall_score)
        
        return overall_score, component_scores
    
    def _evaluate_evidence_strength(self, question: str, answer: str, context: str) -> float:
        """
        Evaluate how well the answer is supported by evidence in the context.
        Returns a score from 0-100.
        """
        prompt = [
            SystemMessage(content=(
                "Bed√∂m hur v√§l svaret st√∂ds av bevis i den tillhandah√•llna kontexten. "
                "Ge en po√§ng fr√•n 0 till 100 d√§r:\n"
                "0 = Inget st√∂d alls i kontexten\n"
                "50 = Delvis st√∂d i kontexten\n"
                "100 = Fullst√§ndigt st√∂d i kontexten med specifika citat eller h√§nvisningar\n"
                "Returnera ENDAST ett heltal mellan 0 och 100."
            )),
            HumanMessage(content=f"Fr√•ga: {question}\n\nSvar: {answer}\n\nKontext: {context}")
        ]
        
        try:
            result = self.llm.invoke(prompt)
            # Extract the numeric score
            score_text = re.search(r'\d+', result.content)
            if score_text:
                score = int(score_text.group())
                return min(max(score, 0), 100)  # Ensure score is between 0-100
            return 50  # Default to medium confidence if parsing fails
        except Exception as e:
            logger.error(f"‚ùå Error evaluating evidence strength: {e}")
            return 50  # Default to medium confidence if evaluation fails
    
    def _evaluate_context_relevance(self, question: str, context: str) -> float:
        """
        Evaluate how relevant the retrieved context is to the question.
        Returns a score from 0-100.
        """
        prompt = [
            SystemMessage(content=(
                "Bed√∂m hur relevant den h√§mtade kontexten √§r f√∂r fr√•gan. "
                "Ge en po√§ng fr√•n 0 till 100 d√§r:\n"
                "0 = Kontexten √§r helt irrelevant f√∂r fr√•gan\n"
                "50 = Kontexten √§r delvis relevant men saknar viktig information\n"
                "100 = Kontexten √§r perfekt relevant och inneh√•ller all n√∂dv√§ndig information\n"
                "Returnera ENDAST ett heltal mellan 0 och 100."
            )),
            HumanMessage(content=f"Fr√•ga: {question}\n\nKontext: {context}")
        ]
        
        try:
            result = self.llm.invoke(prompt)
            # Extract the numeric score
            score_text = re.search(r'\d+', result.content)
            if score_text:
                score = int(score_text.group())
                return min(max(score, 0), 100)  # Ensure score is between 0-100
            return 50  # Default to medium confidence if parsing fails
        except Exception as e:
            logger.error(f"‚ùå Error evaluating context relevance: {e}")
            return 50  # Default to medium confidence if evaluation fails
    
    def _evaluate_answer_completeness(self, question: str, answer: str) -> float:
        """
        Evaluate how completely the answer addresses all aspects of the question.
        Returns a score from 0-100.
        """
        prompt = [
            SystemMessage(content=(
                "Bed√∂m hur fullst√§ndigt svaret adresserar alla aspekter av fr√•gan. "
                "Ge en po√§ng fr√•n 0 till 100 d√§r:\n"
                "0 = Svaret adresserar inte fr√•gan alls\n"
                "50 = Svaret adresserar fr√•gan delvis men missar viktiga aspekter\n"
                "100 = Svaret adresserar alla aspekter av fr√•gan fullst√§ndigt\n"
                "Returnera ENDAST ett heltal mellan 0 och 100."
            )),
            HumanMessage(content=f"Fr√•ga: {question}\n\nSvar: {answer}")
        ]
        
        try:
            result = self.llm.invoke(prompt)
            # Extract the numeric score
            score_text = re.search(r'\d+', result.content)
            if score_text:
                score = int(score_text.group())
                return min(max(score, 0), 100)  # Ensure score is between 0-100
            return 50  # Default to medium confidence if parsing fails
        except Exception as e:
            logger.error(f"‚ùå Error evaluating answer completeness: {e}")
            return 50  # Default to medium confidence if evaluation fails
    
    def _evaluate_internal_consistency(self, answer: str) -> float:
        """
        Evaluate the internal consistency and coherence of the answer.
        Returns a score from 0-100.
        """
        prompt = [
            SystemMessage(content=(
                "Bed√∂m den interna konsistensen och sammanh√§nget i svaret. "
                "Ge en po√§ng fr√•n 0 till 100 d√§r:\n"
                "0 = Svaret √§r mycket inkonsekvent med motsatta p√•st√•enden\n"
                "50 = Svaret har n√•gra mindre inkonsekvenser\n"
                "100 = Svaret √§r helt konsekvent och v√§lstrukturerat\n"
                "Returnera ENDAST ett heltal mellan 0 och 100."
            )),
            HumanMessage(content=f"Svar: {answer}")
        ]
        
        try:
            result = self.llm.invoke(prompt)
            # Extract the numeric score
            score_text = re.search(r'\d+', result.content)
            if score_text:
                score = int(score_text.group())
                return min(max(score, 0), 100)  # Ensure score is between 0-100
            return 50  # Default to medium confidence if parsing fails
        except Exception as e:
            logger.error(f"‚ùå Error evaluating internal consistency: {e}")
            return 50  # Default to medium confidence if evaluation fails
    
    def get_confidence_label(self, score: float) -> str:
        """
        Convert a numeric confidence score to a human-readable label.
        """
        if score >= 90:
            return "Mycket h√∂g"
        elif score >= 75:
            return "H√∂g"
        elif score >= 60:
            return "God"
        elif score >= 40:
            return "M√•ttlig"
        elif score >= 25:
            return "L√•g"
        else:
            return "Mycket l√•g"
    
    def format_confidence_display(self, score: float, component_scores: Dict[str, float]) -> str:
        """
        Format the confidence score and breakdown for display to the user.
        """
        label = self.get_confidence_label(score)
        
        # Map component names to Swedish
        component_names = {
            "evidence": "Evidensstyrka",
            "relevance": "Kontextrelevans",
            "completeness": "Fullst√§ndighet",
            "consistency": "Intern konsistens"
        }
        
        # Format the confidence display
        display = f"\n\n---\n\n**Tillf√∂rlitlighet: {label} ({score}%)**\n\n"
        
        # Add component breakdown if score is below 75%
        if score < 75:
            display += "*Faktorer som p√•verkar tillf√∂rlitligheten:*\n\n"
            for component, component_score in component_scores.items():
                if component_score < 70:  # Only show problematic components
                    display += f"- {component_names[component]}: {component_score}%\n"
        
        return display
    
    def add_confidence_score_to_answer(self, question: str, answer: str, context: List[str]) -> str:
        """
        Calculate confidence score and add it to the answer.
        """
        try:
            score, component_scores = self.calculate_confidence_score(question, answer, context)
            confidence_display = self.format_confidence_display(score, component_scores)
            
            # Add confidence display to the answer
            enhanced_answer = answer + confidence_display
            
            logger.info(f"[ConfidenceScorer] Added confidence score: {score}%")
            return enhanced_answer
        except Exception as e:
            logger.error(f"‚ùå Error adding confidence score: {e}")
            return answer  # Return original answer if scoring fails
